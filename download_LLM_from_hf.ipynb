{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sqrt\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaConfig, LlamaModel, LlamaTokenizer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Config, GPT2Tokenizer, GPT2Model, AutoTokenizer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEmbed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PatchEmbeddingTimeLLM\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/site-packages/transformers/utils/import_utils.py:1594\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m-> 1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/site-packages/transformers/utils/import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/site-packages/transformers/utils/import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1606\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1607\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1608\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cache, DynamicCache, StaticCache\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionMaskConverter\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_flash_attention_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _flash_attention_forward\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     BaseModelOutputWithPast,\n\u001b[1;32m     35\u001b[0m     CausalLMOutputWithPast,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_rope_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ROPE_INIT_FUNCTIONS\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/site-packages/transformers/modeling_flash_attention_utils.py:26\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_flash_attn_2_available, is_flash_attn_greater_or_equal\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_flash_attn_2_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert_padding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m index_first_axis, pad_input, unpad_input  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flash_attn_func, flash_attn_varlen_func\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/site-packages/transformers/utils/import_utils.py:825\u001b[0m, in \u001b[0;36mis_flash_attn_2_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Let's add an extra check to see if cuda is available\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m is_torch_mlu_available()):\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda:\n",
      "File \u001b[0;32m~/envs/llmpy311/lib/python3.11/site-packages/torch/cuda/__init__.py:128\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m device_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# API via `cuInit`\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_getDeviceCount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from math import sqrt\n",
    "from transformers import LlamaConfig, LlamaModel, LlamaTokenizer\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2Model, AutoTokenizer\n",
    "from layers.Embed import PatchEmbeddingTimeLLM\n",
    "from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
    "from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "from layers.StandardNorm import Normalize\n",
    "from layers.fusion import GatedFusion\n",
    "from utils import prompt_helper\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "            \"/data/LLM/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8\",\n",
    "            # 'huggyllama/llama-7b',\n",
    "            trust_remote_code=True,\n",
    "            local_files_only=True\n",
    "        )\n",
    "if tokenizer.eos_token:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "else:\n",
    "    pad_token = '[PAD]'\n",
    "    tokenizer.add_special_tokens({'pad_token': pad_token})\n",
    "    tokenizer.pad_token = pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 20628,   338, 29871, 29906, 29941, 29871, 29946, 29896, 29906]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer([\"Today is 23 412\"], return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd75496a58142fd92f3719e3476692f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 50 files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e48e9649691469abbdfad5f08f9e9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00030.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30ab606bf3343358da2143fb69e9a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257004fab1aa47f39fa9f6c360f67a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1546f962bd4ef3abad3923564ddba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d11a7c69ed44c66b493a9637ed25ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777fc175113e47d693ca5dc042ce802e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2f3704b855409aa9b87eb9621e372f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c163f5fd144fbea035393f5e689355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/c06765cd8c5e838d61284885c48d14286d44f5ecc2aa34d08be2c1f1b63b59ba?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00003-of-00030.safetensors%3B+filename%3D%22model-00003-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvYzA2NzY1Y2Q4YzVlODM4ZDYxMjg0ODg1YzQ4ZDE0Mjg2ZDQ0ZjVlY2MyYWEzNGQwOGJlMmMxZjFiNjNiNTliYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=D3CSpZs4D5%7EmNOASUOUI1ud4obAGM4b-XGz2YpNhOko%7EY1612Enp4wbibgmyE9KY9FtFZ0NOIUrGmYVd5qIwBBXFU0lKV9i%7E5vjJxMTpRSctIBTzfIQe9-geKY3qlBr4pdvDoZrmROWBns1ATJ3chSJ1kinGT02jfX4aKxkLl7GRL8-O1Xfn2miNfv8ClX3bZTUEXeKEn6kqnk5DktWY5WBedcevmmqA0OYDqDvBRVzPSzIg0MV4Zk4q3L56qIEcm-HjAGMNOkA8Fmz%7E5rOHPbT12dq57L64avUtTUIb-1t5nw5WI9IJSRCX74eKqHNt0h65v5V4ue%7Ehut8TOa6jHw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/b8051a0d2e07c7e9fa368a582f6d91d228135fa0c11bdc941a8955fec6a8ba4c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00005-of-00030.safetensors%3B+filename%3D%22model-00005-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvYjgwNTFhMGQyZTA3YzdlOWZhMzY4YTU4MmY2ZDkxZDIyODEzNWZhMGMxMWJkYzk0MWE4OTU1ZmVjNmE4YmE0Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=j60sXQ8Fb3JBXQgGNRPChukP7aNyuJx70WqCEm5Wihw9CQSjSENFl7Jshjfa9h3qI19kDu0moMQVEV4cMO8BMj-0xOvpBRXDGFDB25%7E06P54b7oaCT767wkX5eu4resSOVBQ9ISPUBUVHbOPimzz6FvrWTx-TICM-AzvID3mPgA1hDwfouAZmBo7KJ3WhN7MDIuUKwbIUMntmZohw3Ecumvcy9ogWglNk8L5grg4NcoSoxjYtD839XfjIahzu%7EZzOlmgez9OF6AFjWf6OF-xA3%7EMC7N32eUp2NLOPUcg%7ETTnn32RRhzNcGtZLDJZdwGJ0GIilapTGW99CERi86UONw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/e2e52303706b73fca20c1f4137dcdd16929487b432b805d32e6a0a4967d518d2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-00030.safetensors%3B+filename%3D%22model-00007-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvZTJlNTIzMDM3MDZiNzNmY2EyMGMxZjQxMzdkY2RkMTY5Mjk0ODdiNDMyYjgwNWQzMmU2YTBhNDk2N2Q1MThkMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=hiO2LaWU1o746oFDivLwR3I3jDiSnpMrwkzwHTUiFRkv1sv9k05-k4nQpVn0fzrEJWKkXm8ixBwKrHNWaLp6GOTctxeDF797UosDKqzNJaLpJRt80YcaYfb8RHHgOqvIQZZdkt-QC0M7CGAG5pwULXX2jUPp9oUHDD5oU4QVvSX7MnFibk4lqL1myY18Pdg8s2vdzRvppcWHTxUAI%7EtwFKm5VbdSY2kpngfObiIblLSqbpR7QdifeG8Y2bqRcXKylnP8r39zKuBe3SdYDu5NXsKb5SEr3uFpvChRY1uUE-MZO0eu1WVZwN%7EK8NL-2L4mwXu52PmvkDL4w3nC7DbJuw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc1ed1ec8bb4cbf9142eb0e0820b9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00030.safetensors:  24%|##3       | 1.18G/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dbab0b0aad4e34aaea692cacd361aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00030.safetensors:  28%|##8       | 1.32G/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77683c62bcd455287200f807340a3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00030.safetensors:  27%|##6       | 1.24G/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/4642126f1113a1c3eb42e0b83e965d5b85f12b39931767dba1642cb5630bbce9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00030.safetensors%3B+filename%3D%22model-00002-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvNDY0MjEyNmYxMTEzYTFjM2ViNDJlMGI4M2U5NjVkNWI4NWYxMmIzOTkzMTc2N2RiYTE2NDJjYjU2MzBiYmNlOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=CVsNYVp6hAN%7E8k9ESOxc%7EfuBlj1JGcZssOrXwAcKtuwA%7Echhaa0qDoavsrvnvEypdhb4CrYFm5iPVfRXtltESEDfoUqxYjRd0WDj0HAHuhLChPQ%7EdnnowKA8FPKx2WUicdEHqfAf0aATiCHlW4lC8pxwZttpFXMdyN6KZO%7EcQ6BQhcgFmrZeQShHwqvFpXh3KdUqnSbQ5uLajkgEfUUMuLIozlLMVflfuoxyBUOdktA03pDH23CdLOI5Mjwep9L96XwTDFQMigjuLmvIiISgoHeONMsmK1EC2b%7EGtCCc%7EJW-LkLao97HiDYp6whEOqlQljcCUOnd39ygS6tUoFVlGQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c229b571db94d89bb6133efda6e16a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00030.safetensors:  26%|##6       | 1.22G/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/6240b8784a4236a01656e9af27d09b122417ee83eb2d1a35e46f31456230059f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00008-of-00030.safetensors%3B+filename%3D%22model-00008-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvNjI0MGI4Nzg0YTQyMzZhMDE2NTZlOWFmMjdkMDliMTIyNDE3ZWU4M2ViMmQxYTM1ZTQ2ZjMxNDU2MjMwMDU5Zj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=S5sqoizBiraJF4NqDloEEZ-q-od4Sg6UxBmolNnYEio8A0B8rk7eoICb2wA2Sf2Qtn%7EJepPvG76UWKme4yX5vllED%7EZoXEJ6t7znkJoPhgm90DlmhiN2y44-EegLGc2D2Yz50cqV1AwFnS48rRKQA1vew9h57sVN0D5dbSDkjv5Fxb2LjDcYUjpLUaPRR3xrm-0Trl92d3IdzdqFodQ9iUOM5G88cc8tx6nJaF-N8LAzXgcdtRZAYdFqU%7EcQc2HcFpWf-PbVsrFlW0Tk1sJql2RJfMOUfqfvXIrOPPcKOVHpLYa3mnbk35MreHodnUvnvYt2tCGtn2u5Uz1YMRA9aA__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7156f2fb00834e58b3026003bcb7a584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00030.safetensors:  26%|##5       | 1.28G/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/e2a985e4dcd7538433b512fa14ff23499856a1f925fd947d5b7101ea1f673380?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00004-of-00030.safetensors%3B+filename%3D%22model-00004-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvZTJhOTg1ZTRkY2Q3NTM4NDMzYjUxMmZhMTRmZjIzNDk5ODU2YTFmOTI1ZmQ5NDdkNWI3MTAxZWExZjY3MzM4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=NoV7OCti5vWIZ7kSB8ALEaokjGwZJRzI6w-ZSl6nMKFobvxNZDonvFsEsJDkMLEvGlwPWLC8mgLwD1izrxZVSpKC2UBGQKKGlnzszAn9Ox-kJmYICFPJdD58EQQNn3YxOIPKf82uh01lMIg3%7Eqfh-2DISSF1I3Bpl2q24Zfbwz8UZ7DLbYb0u4N%7Ej1romEFV9Jog4mNk%7EYtAa1TORnq11ypL9LA1eNMEOpmikpcs47AuaK6OJYD8HiTwy8Ni3Aq0qqbI74W92NZPw5gScqJkDdBh%7E%7E5A1oEpYetUVHL10AZ1dpJMTwUeR5JQLMjNVmIvBr7ZplpIddCHklKD2C2qpg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/348cd98f65a4b29af25330445841428a9a16e41569c067e63b7f44af9ea19329?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00006-of-00030.safetensors%3B+filename%3D%22model-00006-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvMzQ4Y2Q5OGY2NWE0YjI5YWYyNTMzMDQ0NTg0MTQyOGE5YTE2ZTQxNTY5YzA2N2U2M2I3ZjQ0YWY5ZWExOTMyOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=qYn0p59mbjOXAIX7YZcq5-9IqeykTv-QtsTk140LN5JjkB6a-zmkO6nKaguUDCieZFVQSDxcAbnLOkCcmR3Tx5Yno1N3OS00OzQMIJP0QEJ4nEKGkqQoDEQbKoZ5rxnKgsQZWxSjbRemqwtERH4Z-f-Ajx-NcyKJHwKQCRcxmz4W%7E%7EN%7EuPwliCrm9P3IYxkWNxq5xtpDm0sUCgtCEABHdH%7EzylT9-nAtia7i-xXqDcYEN5feQVLM40JeGx8wtExnxvMXy1E3%7EXIdxYp%7ExRYKzd5GVUhFSR%7EJgyAqp0ZzOxJ9tpUiXwWvw9FPGqyjBn28YoVQYZVAJPtbEt%7E70YVzgA__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47188b8c0f24a069eb513c6e9f036bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00030.safetensors:  23%|##2       | 1.12G/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611648db049d417f9b31ca06754a9c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00030.safetensors:  24%|##3       | 1.10G/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c3/f6/c3f6f069db0643b77986bcac7e50cea69505dcc7f60706fb8f0678c8130dc942/a3c208883511816be018b3d5c4e90a8c27d9b7d828cbb97d36c05d24d20ada8c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00030.safetensors%3B+filename%3D%22model-00001-of-00030.safetensors%22%3B&Expires=1730512562&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDUxMjU2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2Y2L2MzZjZmMDY5ZGIwNjQzYjc3OTg2YmNhYzdlNTBjZWE2OTUwNWRjYzdmNjA3MDZmYjhmMDY3OGM4MTMwZGM5NDIvYTNjMjA4ODgzNTExODE2YmUwMThiM2Q1YzRlOTBhOGMyN2Q5YjdkODI4Y2JiOTdkMzZjMDVkMjRkMjBhZGE4Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=D3qyVWBCQwmn8Qm5OMFnPMUxYt9-4lKvdhpsvWKbUzM5c%7ECRbkFmezSbgpa-08QoaRVbEzoAdp7yU5e3Ly-KHIWd5du88yopzb4VhMPEus-Gu6ghNcwd1jmpEr5l0bunLAO3%7E5lDaIVjMisbvJCoICg7IMkXaxgSCTEl7NEXeRKD0gL36-FCwnLHUcpeerevLsqojv-lgiJ8txO%7EZe5-bYZr3x0SLZc2VsVkRVFK6eVKJFOcgyUV7suWoeSklUQ1Of9S4VaAC-a1DlEhtAaeOrzNWJld7CSUYolZDir5OOuJhoR1wiQgf%7ElDiru0DoPLcjJYxuxyuq1gWjrJdck5ew__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b004a9d4fbd241969a5a37e689d1b7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00030.safetensors:  24%|##4       | 1.12G/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcf6dacd54c4d9fa9fa51714072d420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23406a19c3414fdb81d6d9f7f1e621a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e619dffb4a1547bdb9533c51a34658c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9d646971eb482db9f5caa2ee6beaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615452b8b0644cf7a56cbc18b13960fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320b8bc3867d495fb53d73401998db94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88bbf97d82d400a84131b60da74c228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa0604709ff4d46a5c0ba263541a6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7681cc28f143a48ac4f5303833d5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(repo_id=\"meta-llama/Llama-3.1-70B-Instruct\", cache_dir='/data/LLMs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 15:28:10.406811: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 15:28:11.175826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parameter config in `BatteryLifeLLM(config)` should be an instance of class `PretrainedConfig`. To create a model from a pretrained model use `model = BatteryLifeLLM.from_pretrained(PRETRAINED_MODEL_NAME)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBatteryLifeLLMUtils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_BatteryLifeLLM\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatteryElectrochemicalConfig\n\u001b[1;32m      3\u001b[0m battery_config \u001b[38;5;241m=\u001b[39m BatteryElectrochemicalConfig({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m----> 4\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mBatteryLifeLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbattery_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mconfig_class)\n",
      "File \u001b[0;32m~/python_work/transformers/src/transformers/modeling_utils.py:1303\u001b[0m, in \u001b[0;36mPreTrainedModel.__init__\u001b[0;34m(self, config, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter config in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(config)` should be an instance of class \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`PretrainedConfig`. To create a model from a pretrained model use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.from_pretrained(PRETRAINED_MODEL_NAME)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;66;03m# Save config and origin of the pretrained weights if given in model\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   1310\u001b[0m     config, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mget_default_dtype(), check_device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter config in `BatteryLifeLLM(config)` should be an instance of class `PretrainedConfig`. To create a model from a pretrained model use `model = BatteryLifeLLM.from_pretrained(PRETRAINED_MODEL_NAME)`"
     ]
    }
   ],
   "source": [
    "from models.BatteryLifeLLM import BatteryLifeLLM\n",
    "from BatteryLifeLLMUtils.configuration_BatteryLifeLLM import BatteryElectrochemicalConfig\n",
    "battery_config = BatteryElectrochemicalConfig()\n",
    "a = BatteryLifeLLM()\n",
    "print(a.config_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data = json.load(open('./dataset/MIT_LFP_Batch9_cell_data.json'))\n",
    "len(data)\n",
    "\n",
    "import os\n",
    "a = os.listdir('./dataset/MIT_dataset')\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计一下MIT数据集有多少种不同的prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "from Prompts import HUST_protocol_prompt, MIT_all_protocol_prompt\n",
    "prompts = HUST_protocol_prompt.HUST_protocol_prompt.Protocols_prompts\n",
    "prompt_keys = {}\n",
    "for key, value in prompts.items():\n",
    "    prompt_keys[value] = prompt_keys.get(value, []) + [key]\n",
    "\n",
    "for key, value in prompt_keys.items():\n",
    "    if len(value) > 1:\n",
    "        print(key, value)\n",
    "print(len(prompt_keys))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
